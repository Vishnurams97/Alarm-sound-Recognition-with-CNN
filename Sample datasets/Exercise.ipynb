{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import scipy.io.wavfile as wav\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pyaudio\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import glob\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "import sounddevice as sd\n",
    "from keras.models import Sequential,load_model\n",
    "import librosa.util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import soundfile as sf\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# RATE = 22050\n",
    "# RECORD_SECONDS = 5\n",
    "# CHUNKSIZE = 1024\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "# #Loop\n",
    "# for i in range(50):\n",
    "#     stream = p.open(format=pyaudio.paFloat32, channels=1, rate=RATE, input=True, frames_per_buffer=CHUNKSIZE)\n",
    "\n",
    "#     frames = [] # A python-list of chunks(numpy.ndarray)\n",
    "#     for _ in range(0, int(RATE / CHUNKSIZE * RECORD_SECONDS)):\n",
    "#         data = stream.read(CHUNKSIZE)\n",
    "#         frames.append(numpy.fromstring(data, dtype=numpy.float32))\n",
    "\n",
    "#     #Convert the list of numpy-arrays into a 1D array (column-wise)\n",
    "#     numpydata = numpy.hstack(frames)\n",
    "\n",
    "#     # close stream\n",
    "#     stream.stop_stream()\n",
    "#     wav.write('n'+str(i)+'.wav',RATE,numpydata)\n",
    "#     print(\"Sample_number: \",i)\n",
    "# stream.close()\n",
    "# p.terminate()\n",
    "output_res = ['Alarm','Noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('current_model.h5')\n",
    "two_layer_model = load_model('100.0model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\display.py\u001b[0m in \u001b[0;36mspecshow\u001b[1;34m(data, x_coords, y_coords, x_axis, y_axis, sr, hop_length, fmin, fmax, bins_per_octave, ax, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;31m# Get the x and y coordinates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[0my_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__mesh_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m     \u001b[0mx_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__mesh_coords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_coords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__check_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RATE = 22050\n",
    "sr = 22050\n",
    "RECORD_SECONDS = 2.975\n",
    "CHUNKSIZE = 655\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "while True:\n",
    "    stream = p.open(format=pyaudio.paFloat32, channels=1, rate=RATE, input=True, frames_per_buffer=CHUNKSIZE)\n",
    "\n",
    "    frames = [] # A python-list of chunks(numpy.ndarray)\n",
    "\n",
    "    for _ in range(0, int(RATE / CHUNKSIZE * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNKSIZE)\n",
    "        frames.append(np.fromstring(data, dtype=np.float32))\n",
    "\n",
    "    #Convert the list of numpy-arrays into a 1D array (column-wise)\n",
    "    numpydata = np.hstack(frames)\n",
    "    # close stream\n",
    "    stream.stop_stream()\n",
    "    numpydata = numpydata[:-1]\n",
    "#     wav.write('p'+str(1000)+'.wav',RATE,numpydata)\n",
    "#     y,sr = librosa.load('p'+str(1000)+'.wav', duration=2.97)\n",
    "    ps = librosa.feature.melspectrogram(y=numpydata, sr=sr)\n",
    "    ps = ps.reshape(128,128,1)\n",
    "    predictions = model.predict(np.array([ps,]))\n",
    "    predictions1 = two_layer_model.predict(np.array([ps,]))\n",
    "    print(\"Predictions:\",predictions)\n",
    "#     if(predictions[0][0]>=0.50):\n",
    "#         print(\"Alarm by 1 layer\")\n",
    "#     else:\n",
    "#         print(\"Noise by 1 layer\")\n",
    "    print(\"Predictions1:\",output_res[np.argmax(predictions1)])\n",
    "#     if(output_res[np.argmax(predictions)]=='Alarm'):\n",
    "# #         librosa.util.peak_pick(x, pre_max, post_max, pre_avg, post_avg, delta, wait)\n",
    "#         onset_env = librosa.onset.onset_strength(y=numpydata, sr=sr, hop_length=512, aggregate=np.median)\n",
    "#         peaks = librosa.util.peak_pick(onset_env, 3, 3, 3, 5, 0.5, 35)\n",
    "#     #     print(peaks,end=\"\")\n",
    "#         times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "#                                    sr=sr, hop_length=512)\n",
    "#     #     #     wait = 100\n",
    "#         if(len(peaks)==0 or len(peaks)==1):\n",
    "#             print('\\nAbnormal as number of peaks detected is {}',format(len(peaks)))\n",
    "#         else:\n",
    "#             val = times[peaks]\n",
    "# #             print(val)\n",
    "#             if(val[1]-val[0]<=1 and len(peaks)>3):\n",
    "#                 print('\\nCondn: abnormal!!')\n",
    "# #                 plt.figure()\n",
    "# #                 ax = plt.subplot(2, 1, 2)\n",
    "# #                 D = librosa.stft(numpydata)\n",
    "# #                 librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max),\n",
    "# #                                          y_axis='log', x_axis='time')\n",
    "# #                 plt.subplot(2, 1, 1, sharex=ax)\n",
    "# #                 plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "# #                 plt.vlines(times[peaks], 0,\n",
    "# #                            onset_env.max(), color='r', alpha=0.8,\n",
    "# #                            label='Selected peaks')\n",
    "# #                 plt.legend(frameon=True, framealpha=0.8)\n",
    "# #                 plt.axis('tight')\n",
    "# #                 plt.tight_layout()\n",
    "# #                 break\n",
    "#             else:\n",
    "#                 print('>>',end=\"\")\n",
    "        \n",
    "#     else:\n",
    "#         print(\"..\",end=\"\")\n",
    "    \n",
    "stream.close()\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "(128, 128)\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RATE = 22050\n",
    "sr = RATE\n",
    "RECORD_SECONDS = 2.975\n",
    "CHUNKSIZE = 1024\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "#Loop\n",
    "\n",
    "stream = p.open(format=pyaudio.paFloat32, channels=1, rate=RATE, input=True, frames_per_buffer=CHUNKSIZE)\n",
    "\n",
    "frames = [] # A python-list of chunks(numpy.ndarray)\n",
    "\n",
    "for _ in range(0, int(RATE / CHUNKSIZE * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNKSIZE)\n",
    "    frames.append(np.fromstring(data, dtype=np.float32))\n",
    "\n",
    "#Convert the list of numpy-arrays into a 1D array (column-wise)\n",
    "numpydata = np.hstack(frames)\n",
    "\n",
    "numpydata = numpydata[:-1]\n",
    "# close stream\n",
    "stream.stop_stream()\n",
    "wav.write('p'+str(1000)+'.wav',RATE,numpydata)\n",
    "stream.close()\n",
    "p.terminate()\n",
    "ps_ = librosa.feature.melspectrogram(y=numpydata, sr=sr)\n",
    "print(ps_.shape)\n",
    "y,sr = librosa.load('p'+str(1000)+'.wav', duration=2.97)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0e8e42d38d67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(ps,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[2,6,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.normalization.BatchNormalization at 0x181e086e780>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', \n",
    "                                beta_regularizer=None, gamma_regularizer=None,\n",
    "                                beta_constraint=None, gamma_constraint=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
